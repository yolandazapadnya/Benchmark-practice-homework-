{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVq8V0VlLvwE"
   },
   "source": [
    "# DEMO de Elaboración y Ejecución de Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrg1itwCwfCM"
   },
   "outputs": [],
   "source": [
    "# Poned vuestra API KEY de groq aquí:\n",
    "groq_api_key = \"[removed for privacy reasons]\" #add yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86GvZgsNMLuT"
   },
   "source": [
    "###   Clase Benchmark + Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NCMl0PLmcZHp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: groq in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (2.11.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/yolandaxavier/Library/Python/3.10/lib/python/site-packages (from groq) (4.13.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/yolandaxavier/Library/Python/3.10/lib/python/site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2022.9.24)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
      "Call stack:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/__main__.py\", line 31, in <module>\n",
      "    sys.exit(_main())\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='25.0.1'),)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.0/198.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-3.4.1 requests-2.32.3 urllib3-2.3.0\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Library/Frameworks/Python.framework/Versions/3.10/bin/pip'\n",
      "Call stack:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/__main__.py\", line 31, in <module>\n",
      "    sys.exit(_main())\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
      "    self.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
      "    self.emit(record)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='25.0.1'),)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq tabulate\n",
    "%pip install requests\n",
    "import json, re, requests\n",
    "from groq import Groq\n",
    "from tabulate import tabulate\n",
    "\n",
    "class LLMBenchmark:\n",
    "    def __init__(self, groq_api_key, models = [\"llama-3.2-90b-vision-preview\", \"llama-3.3-70b-versatile\", \"mixtral-8x7b-32768\", \"gemma2-9b-it\", \"llama-3.2-3b-preview\"]):\n",
    "        self.groq_api_key = groq_api_key\n",
    "        self.groq_client = Groq(api_key=groq_api_key)\n",
    "        self.questions = []\n",
    "        self.models = models\n",
    "\n",
    "    def add_question(self, question, options, correct_answer):\n",
    "        # Formateamos las opciones con letras\n",
    "        formatted_options = {chr(65 + i): option for i, option in enumerate(options)}\n",
    "        formatted_options_inverse = {option : chr(65 + i) for i, option in enumerate(options)}\n",
    "        self.questions.append({\n",
    "            \"question\": question,\n",
    "            \"options\": formatted_options,\n",
    "            \"correct_answer\": formatted_options_inverse[correct_answer] if correct_answer in formatted_options_inverse else correct_answer\n",
    "        })\n",
    "\n",
    "    def print_groq_models(self):\n",
    "        url = \"https://api.groq.com/openai/v1/models\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.groq_api_key}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(response.json())\n",
    "\n",
    "    def add_model(self, *model_names):\n",
    "        self.models.extend(model_names)\n",
    "\n",
    "    def print_debug(self, message, debug):\n",
    "        if debug:\n",
    "            print(message)\n",
    "\n",
    "    def run_benchmark(self, debug=False):\n",
    "        results = {}\n",
    "        for model_name in self.models:\n",
    "            correct_predictions = 0\n",
    "            for question_data in self.questions:\n",
    "                question = question_data['question']\n",
    "                options = question_data['options']\n",
    "                correct_answer = question_data['correct_answer']\n",
    "\n",
    "                # Construimos el prompt con las opciones\n",
    "                options_text = \"\\n\".join([f\"{label}: {option}\" for label, option in options.items()])\n",
    "                prompt = f\"{question}\\nOpciones:\\n{options_text}\\n\\nPor favor, elige la letra de la opción correcta y responde solo con esa letra y nada más.\"\n",
    "\n",
    "                try:\n",
    "                    chat_completion = self.groq_client.chat.completions.create(\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                        model=model_name,\n",
    "                        max_tokens=50,\n",
    "                        temperature=0,\n",
    "                    )\n",
    "                    model_answer = chat_completion.choices[0].message.content.strip().upper()\n",
    "\n",
    "                    # Validar la respuesta con regex\n",
    "                    if correct_answer.upper() in model_answer:\n",
    "                        correct_predictions += 1\n",
    "                        self.print_debug(f\"✅ Model: {model_name} | Question: {question} | Answer: {model_answer} | Correct: {correct_answer}\", debug)\n",
    "                    else:\n",
    "                        self.print_debug(f\"❌ Model: {model_name} | Question: {question} | Answer: {model_answer} | Correct: {correct_answer}\", debug)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error querying {model_name}: {e}\")\n",
    "\n",
    "            # Calcula la tasa de aciertos\n",
    "            total_questions = len(self.questions)\n",
    "            accuracy = correct_predictions / total_questions if total_questions else 0\n",
    "            results[model_name] = (correct_predictions, total_questions, accuracy)\n",
    "\n",
    "        # Imprimir resultados en una tabla\n",
    "        headers = [\"Modelo\", \"Respuestas correctas\", \"Exactitud\"]\n",
    "        table = [[model, f\"{correct}/{total}\", f\"{accuracy:.2%}\"] for model, (correct, total, accuracy) in results.items()]\n",
    "        print(tabulate(table, headers=headers, tablefmt='grid'))\n",
    "        #return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HASABXbTzeCx"
   },
   "source": [
    "###   Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gzRPuft0doqj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model: llama-3.2-90b-vision-preview | Question: ¿Cuál es la capital de Francia? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-90b-vision-preview | Question: ¿Cuál es el río más largo del mundo? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-90b-vision-preview | Question: ¿En qué año se descubrió América? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-90b-vision-preview | Question: ¿Cuál es la fórmula química del agua? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.3-70b-versatile | Question: ¿Cuál es la capital de Francia? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.3-70b-versatile | Question: ¿Cuál es el río más largo del mundo? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.3-70b-versatile | Question: ¿En qué año se descubrió América? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.3-70b-versatile | Question: ¿Cuál es la fórmula química del agua? | Answer: A | Correct: A\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "✅ Model: gemma2-9b-it | Question: ¿Cuál es la capital de Francia? | Answer: A | Correct: A\n",
      "✅ Model: gemma2-9b-it | Question: ¿Cuál es el río más largo del mundo? | Answer: A | Correct: A\n",
      "✅ Model: gemma2-9b-it | Question: ¿En qué año se descubrió América? | Answer: A | Correct: A\n",
      "✅ Model: gemma2-9b-it | Question: ¿Cuál es la fórmula química del agua? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-3b-preview | Question: ¿Cuál es la capital de Francia? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-3b-preview | Question: ¿Cuál es el río más largo del mundo? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-3b-preview | Question: ¿En qué año se descubrió América? | Answer: A | Correct: A\n",
      "✅ Model: llama-3.2-3b-preview | Question: ¿Cuál es la fórmula química del agua? | Answer: A | Correct: A\n",
      "+------------------------------+------------------------+-------------+\n",
      "| Modelo                       | Respuestas correctas   | Exactitud   |\n",
      "+==============================+========================+=============+\n",
      "| llama-3.2-90b-vision-preview | 4/4                    | 100.00%     |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.3-70b-versatile      | 4/4                    | 100.00%     |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| mixtral-8x7b-32768           | 0/4                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| gemma2-9b-it                 | 4/4                    | 100.00%     |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.2-3b-preview         | 4/4                    | 100.00%     |\n",
      "+------------------------------+------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "llm_benchmark_test = LLMBenchmark(groq_api_key)\n",
    "llm_benchmark_test.add_question(\"¿Cuál es la capital de Francia?\", [\"París\", \"Roma\", \"Berlín\"], \"A\")\n",
    "llm_benchmark_test.add_question(\"¿Cuál es el río más largo del mundo?\", [\"Nilo\", \"Amazonas\", \"Danubio\"], \"Nilo\")\n",
    "llm_benchmark_test.add_question(\"¿En qué año se descubrió América?\", [\"1492\", \"1776\", \"1642\"], \"1492\")\n",
    "llm_benchmark_test.add_question(\"¿Cuál es la fórmula química del agua?\", [\"H2O\", \"CO2\", \"NaCl\"], \"A\")\n",
    "llm_benchmark_test.run_benchmark(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTJQ_RV6lXle"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model: llama-3.2-90b-vision-preview | Question: ¿Cuál es el elemento químico más abundante en la corteza terrestre? | Answer: A | Correct: A\n",
      "❌ Model: llama-3.2-90b-vision-preview | Question: ¿Cuál es la derivada de x^2? | Answer: A | Correct: 5x\n",
      "❌ Model: llama-3.2-90b-vision-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.2-90b-vision-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.2-90b-vision-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "✅ Model: llama-3.3-70b-versatile | Question: ¿Cuál es el elemento químico más abundante en la corteza terrestre? | Answer: A | Correct: A\n",
      "❌ Model: llama-3.3-70b-versatile | Question: ¿Cuál es la derivada de x^2? | Answer: A | Correct: 5x\n",
      "❌ Model: llama-3.3-70b-versatile | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.3-70b-versatile | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.3-70b-versatile | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "❌ Model: gemma2-9b-it | Question: ¿Cuál es el elemento químico más abundante en la corteza terrestre? | Answer: B | Correct: A\n",
      "❌ Model: gemma2-9b-it | Question: ¿Cuál es la derivada de x^2? | Answer: A | Correct: 5x\n",
      "❌ Model: gemma2-9b-it | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: gemma2-9b-it | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: gemma2-9b-it | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.2-3b-preview | Question: ¿Cuál es el elemento químico más abundante en la corteza terrestre? | Answer: B | Correct: A\n",
      "❌ Model: llama-3.2-3b-preview | Question: ¿Cuál es la derivada de x^2? | Answer: A | Correct: 5x\n",
      "❌ Model: llama-3.2-3b-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.2-3b-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "❌ Model: llama-3.2-3b-preview | Question: Explica el concepto de inflación. | Answer: A | Correct: Variaciones en el tipo de cambio.\n",
      "+------------------------------+------------------------+-------------+\n",
      "| Modelo                       | Respuestas correctas   | Exactitud   |\n",
      "+==============================+========================+=============+\n",
      "| llama-3.2-90b-vision-preview | 1/5                    | 20.00%      |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.3-70b-versatile      | 1/5                    | 20.00%      |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| mixtral-8x7b-32768           | 0/5                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| gemma2-9b-it                 | 0/5                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.2-3b-preview         | 0/5                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "llm_benchmark_test2 = LLMBenchmark(groq_api_key)\n",
    "llm_benchmark_test2.add_question(\"¿Cuál es el elemento químico más abundante en la corteza terrestre?\", [\"Oxígeno\", \"Silicio\", \"Aluminio\"], \"Oxígeno\")\n",
    "llm_benchmark_test2.run_benchmark(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n23Hj86cMUX_"
   },
   "source": [
    "#   CÓDIGO PRÁCTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "id": "pP_SQnqA7u1j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Model: llama-3.2-90b-vision-preview | Question: Analiza la complejidad computacional del algoritmo de Dijkstra para encontrar el camino más corto en un grafo ponderado, considerando diferentes estructuras de datos para representar el grafo (listas de adyacencia, matrices de adyacencia) y la implementación de la cola de prioridad. | Answer: B | Correct: A\n",
      "❌ Model: llama-3.3-70b-versatile | Question: Analiza la complejidad computacional del algoritmo de Dijkstra para encontrar el camino más corto en un grafo ponderado, considerando diferentes estructuras de datos para representar el grafo (listas de adyacencia, matrices de adyacencia) y la implementación de la cola de prioridad. | Answer: B | Correct: A\n",
      "Error querying mixtral-8x7b-32768: Error code: 400 - {'error': {'message': 'The model `mixtral-8x7b-32768` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}\n",
      "❌ Model: gemma2-9b-it | Question: Analiza la complejidad computacional del algoritmo de Dijkstra para encontrar el camino más corto en un grafo ponderado, considerando diferentes estructuras de datos para representar el grafo (listas de adyacencia, matrices de adyacencia) y la implementación de la cola de prioridad. | Answer: B | Correct: A\n",
      "❌ Model: llama-3.2-3b-preview | Question: Analiza la complejidad computacional del algoritmo de Dijkstra para encontrar el camino más corto en un grafo ponderado, considerando diferentes estructuras de datos para representar el grafo (listas de adyacencia, matrices de adyacencia) y la implementación de la cola de prioridad. | Answer: B | Correct: A\n",
      "+------------------------------+------------------------+-------------+\n",
      "| Modelo                       | Respuestas correctas   | Exactitud   |\n",
      "+==============================+========================+=============+\n",
      "| llama-3.2-90b-vision-preview | 0/1                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.3-70b-versatile      | 0/1                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| mixtral-8x7b-32768           | 0/1                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| gemma2-9b-it                 | 0/1                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n",
      "| llama-3.2-3b-preview         | 0/1                    | 0.00%       |\n",
      "+------------------------------+------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "llm_benchmark_test2 = LLMBenchmark(groq_api_key)\n",
    "llm_benchmark_test2.add_question(\"Analiza la complejidad computacional del algoritmo de Dijkstra para encontrar el camino más corto en un grafo ponderado, considerando diferentes estructuras de datos para representar el grafo (listas de adyacencia, matrices de adyacencia) y la implementación de la cola de prioridad.\", [\"Complejidad de O(E log V), siendo E el número de aristas y V el número de vértices del grafo. Dependiendo de la implementación de la cola de prioridad y la representación del grafo.\", \"Complejidad de O(V^2) con matriz de adyacencia, O(E log V) con lista de adyacencia y cola de prioridad.\", \"Algoritmo con complejidad polinomial, pero su eficiencia depende de la elección de la cola de prioridad y del tamaño del grafo.\",\"La complejidad depende de la distribución de los pesos y la cantidad de nodos del grafo.\"], \"A\")\n",
    "llm_benchmark_test2.run_benchmark(True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP7EMtniiGhcQSnt5Y0Lvjb",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
